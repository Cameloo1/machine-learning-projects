# News Headline Sentiment Project

An end-to-end NLP workflow for classifying financial news headlines for major tickers into **Bullish / Neutral / Bearish** sentiment. The project fetches raw headlines from NewsAPI.org, supports manual labeling, and trains both Logistic Regression and Linear SVM models with TF-IDF + ticker one-hot features.

## Project Structure

```
news_sentiment_project/
├── data/
│   ├── raw_headlines.csv
│   └── labeled_headlines.csv
├── notebooks/
│   └── 01_news_headline_sentiment.ipynb
├── reports/
│   ├── figures/
│   │   ├── cm_logreg.png
│   │   ├── cm_linearsvc.png
│   │   ├── model_metrics.png
│   │   ├── per_class_f1.png
│   │   ├── top_tokens_logreg.png
│   │   └── top_tokens_linearsvc.png
│   └── model_comparison.md
├── src/
│   ├── __init__.py
│   ├── config.py
│   ├── data_fetch.py
│   ├── manual_scrape.py
│   ├── preprocess.py
│   ├── explain.py
│   └── train.py
├── models/
│   ├── logreg_model.pkl
│   ├── linearsvc_model.pkl
│   ├── tfidf_vectorizer.pkl
│   └── ticker_encoder.pkl
├── requirements.txt
├── .env                 # contains NEWS_API_KEY (never commit your real key)
└── README.md
```

## Quickstart

1. `python -m venv .venv && .venv\\Scripts\\activate`
2. `pip install -r requirements.txt`
3. Create `.env` with `NEWS_API_KEY=your_key`.
4. Run the notebook `notebooks/01_news_headline_sentiment.ipynb`.
   - Step 1 fetches raw headlines to `data/raw_headlines.csv`.
   - Manually label ~250 rows and save to `data/labeled_headlines.csv`.
   - Continue the notebook to preprocess, train, evaluate, explain, and compare models.

### Manual scraping fallback

- If the NewsAPI key is missing/invalid or you prefer to skip the API, set `USE_MANUAL_SCRAPE=1` (env var or `os.environ[...]` inside the notebook) before running Step 1.
- The fallback scraper (Google News + Yahoo Finance) respects polite delays and outputs the same schema as the API so downstream labeling/modeling stays identical.

Key outputs (figures, reports, trained models) land in the `reports/` and `models/` folders for easy review or sharing.

## Model Performance Summary

### Results Overview

**Linear SVC** outperforms **Logistic Regression** across all metrics:
- **Accuracy**: 57.4% vs 50.0% (test set: 54 samples)
- **Macro F1**: 0.577 vs 0.502
- **Weighted F1**: 0.575 vs 0.500

### Per-Class Performance

Linear SVC shows strongest performance on **Neutral** sentiment (F1: 0.667), while both models struggle with **Bullish↔Bearish** confusion. This suggests ambiguous headlines or insufficient training data for these classes.

**Top interpretable features** align with financial sentiment:
- **Bullish**: "buy", "market", "live"
- **Bearish**: "downgrade", "slides", "cuts", "losing"

### Current Limitations

**Not production-ready** due to:
- Moderate accuracy (57.4% is only ~7 points above random for 3 classes)
- Small test set (54 samples) limits statistical confidence
- Persistent Bullish↔Bearish confusion across both models
- Class imbalance in current dataset (20 Bullish, 17 Neutral, 17 Bearish)

### Recommendations for Improvement

**Best use case**: Research/prototype stage — suitable as a first-pass filter with human review for high-stakes decisions.

**To improve reliability**:
1. **Expand dataset**: Target 500–1000+ labeled examples with balanced classes (~150–200 per class)
2. **Feature engineering**: Add financial lexicons (e.g., Loughran-McDonald), experiment with embeddings
3. **Model improvements**: Try ensemble methods, cross-validation, threshold tuning per class
4. **Validation**: Use larger test sets (20–30%), track performance over time

See `reports/model_comparison.md` and `reports/figures/` for detailed metrics, confusion matrices, and explainability visualizations.

## Repository Contents

### What's Included
- Source code (`src/`)
- Notebooks (`notebooks/`)
- Configuration and requirements
- Documentation (README, reports structure)

### What's Excluded (via `.gitignore`)
- **Trained models** (`.pkl` files): Can be regenerated by running the pipeline
- **Data files** (`raw_headlines.csv`, `labeled_headlines.csv`): 
  - Can be regenerated via API/scraping
  - May contain copyrighted content
  - Users should create their own labeled dataset
- **Environment files** (`.env`): Contains API keys — never commit secrets

### What's Included
- **Generated reports/figures**: Included for easy review and sharing (confusion matrices, metrics, explainability plots)

### Regenerating Artifacts
Excluded files (models and data) can be regenerated by:
1. Setting up your `.env` with `NEWS_API_KEY` (or use manual scraping)
2. Running the notebook or `scripts/run_end_to_end.py`
3. The pipeline will create all models, reports, and figures automatically

Reports and figures are included in the repository for immediate review, but can also be regenerated if needed.


