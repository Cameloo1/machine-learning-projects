{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Short-Term Price Move Classifier\n",
        "A compact, reproducible walkthrough for predicting next-day SPY direction using purely backward-looking technical indicators and a trio of classic ML models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Roadmap\n",
        "- Load and visualize adjusted OHLCV data from Yahoo Finance\n",
        "- Engineer strictly causal technical factors and build the binary target\n",
        "- Respect time ordering for training/testing and compare against a majority baseline\n",
        "- Fit Logistic Regression, Random Forest, and Gradient Boosting models\n",
        "- Inspect ROC curves, coefficients, and feature importances before wrapping up with key takeaways\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd  # type: ignore\n",
        "import matplotlib.pyplot as plt  # type: ignore\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "\n",
        "from short_term_price_classifier.config import (\n",
        "    DATA_START,\n",
        "    DEFAULT_TICKER,\n",
        "    RANDOM_STATE,\n",
        "    TARGET_COLUMN,\n",
        "    TRAIN_FRACTION,\n",
        ")\n",
        "from short_term_price_classifier.data_loader import load_ohlcv\n",
        "from short_term_price_classifier.features import build_feature_dataset\n",
        "from short_term_price_classifier.modeling import (\n",
        "    compute_baseline_predictions,\n",
        "    time_based_train_test_split,\n",
        "    train_gradient_boosting,\n",
        "    train_logistic_regression,\n",
        "    train_random_forest,\n",
        ")\n",
        "from short_term_price_classifier.evaluation import (\n",
        "    evaluate_classifier,\n",
        "    plot_feature_importances,\n",
        "    plot_logistic_coefficients,\n",
        "    plot_roc_curve,\n",
        "    print_evaluation_report,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_df = load_ohlcv(DEFAULT_TICKER, DATA_START)\n",
        "print(f\"Rows: {len(raw_df):,} from {raw_df.index.min().date()} to {raw_df.index.max().date()} for {DEFAULT_TICKER}\")\n",
        "raw_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = raw_df[\"Close\"].plot(title=f\"{DEFAULT_TICKER} Adjusted Close\", figsize=(10, 4))\n",
        "ax.set_ylabel(\"Price ($)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_df, feature_cols = build_feature_dataset(raw_df)\n",
        "print(f\"Feature rows after dropping NaNs: {len(feature_df):,}\")\n",
        "feature_df[feature_cols + [TARGET_COLUMN]].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_counts = feature_df[TARGET_COLUMN].value_counts().sort_index()\n",
        "print(\"Class counts:\\n\", target_counts)\n",
        "print(\"Class share:\\n\", (target_counts / target_counts.sum()).round(3))\n",
        "(target_counts / target_counts.sum()).plot(kind=\"bar\", title=\"Target Distribution\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = time_based_train_test_split(\n",
        "    df=feature_df,\n",
        "    feature_cols=feature_cols,\n",
        "    target_col=TARGET_COLUMN,\n",
        "    train_fraction=TRAIN_FRACTION,\n",
        ")\n",
        "print(f\"Train samples: {len(X_train):,}, Test samples: {len(X_test):,}\")\n",
        "\n",
        "metrics_summary = {}\n",
        "\n",
        "y_pred_baseline = compute_baseline_predictions(y_train, y_test)\n",
        "baseline_metrics = evaluate_classifier(y_test, y_pred_baseline)\n",
        "print_evaluation_report(\"Baseline (Majority Class)\", baseline_metrics)\n",
        "metrics_summary[\"Baseline\"] = baseline_metrics\n",
        "baseline_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_reg, scaler = train_logistic_regression(X_train, y_train, RANDOM_STATE)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "log_pred = log_reg.predict(X_test_scaled)\n",
        "log_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
        "log_metrics = evaluate_classifier(y_test, log_pred, log_proba)\n",
        "print_evaluation_report(\"Logistic Regression\", log_metrics)\n",
        "metrics_summary[\"Logistic Regression\"] = log_metrics\n",
        "log_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_roc_curve(y_test, log_proba, \"Logistic Regression ROC\")\n",
        "plot_logistic_coefficients(feature_cols, log_reg.coef_[0], \"Logistic Regression Coefficients\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model = train_random_forest(X_train, y_train, RANDOM_STATE)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "rf_metrics = evaluate_classifier(y_test, rf_pred, rf_proba)\n",
        "print_evaluation_report(\"Random Forest\", rf_metrics)\n",
        "metrics_summary[\"Random Forest\"] = rf_metrics\n",
        "rf_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_roc_curve(y_test, rf_proba, \"Random Forest ROC\")\n",
        "plot_feature_importances(feature_cols, rf_model.feature_importances_, \"Random Forest Feature Importance\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb_model = train_gradient_boosting(X_train, y_train, RANDOM_STATE)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "gb_proba = gb_model.predict_proba(X_test)[:, 1]\n",
        "gb_metrics = evaluate_classifier(y_test, gb_pred, gb_proba)\n",
        "print_evaluation_report(\"Gradient Boosting\", gb_metrics)\n",
        "metrics_summary[\"Gradient Boosting\"] = gb_metrics\n",
        "gb_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_roc_curve(y_test, gb_proba, \"Gradient Boosting ROC\")\n",
        "plot_feature_importances(feature_cols, gb_model.feature_importances_, \"Gradient Boosting Feature Importance\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_df = pd.DataFrame(metrics_summary).T\n",
        "summary_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways\n",
        "- All models modestly outperform the majority baseline, though edge remains slim (ROC AUC often hovering just above 0.5).\n",
        "- Tree ensembles highlight the importance of short-term momentum, volatility, and RSI; logistic regression yields interpretable coefficients for the same signals.\n",
        "- Obvious extensions: incorporate regime detection, multi-asset universes, alternative holding periods, or richer risk-management overlays.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
