{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic SOC Alert Anomaly Detector Walkthrough\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook roadmap\n",
        "\n",
        "1. Configure environment & imports\n",
        "2. Generate a synthetic SOC dataset and inspect distributions\n",
        "3. Split into train/test using only normal events for training\n",
        "4. Train IsolationForest and OneClassSVM\n",
        "5. Evaluate metrics (ROC AUC, precision@k, confusion matrices)\n",
        "6. Interpret results with global correlations and local z-score explanations\n",
        "7. Produce inline visualizations (score histograms, confusion matrices, feature deviations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from soc_anomaly.config import (\n",
        "    DEFAULT_ANOMALY_FRACTION,\n",
        "    DEFAULT_EVENTS_PER_USER,\n",
        "    DEFAULT_N_USERS,\n",
        "    DEFAULT_RANDOM_STATE,\n",
        ")\n",
        "from soc_anomaly.data_generation import generate_synthetic_soc_dataset\n",
        "from soc_anomaly.anomaly_detection import (\n",
        "    FEATURE_COLS,\n",
        "    LABEL_COL,\n",
        "    compute_feature_stats,\n",
        "    evaluate_model,\n",
        "    explain_top_anomalies,\n",
        "    global_feature_correlations,\n",
        "    isolation_forest_scores,\n",
        "    load_dataset,\n",
        "    oneclass_svm_scores,\n",
        "    prepare_train_test,\n",
        "    train_isolation_forest,\n",
        "    train_oneclass_svm,\n",
        ")\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "plt.rcParams[\"font.size\"] = 11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_USERS = DEFAULT_N_USERS\n",
        "EVENTS_PER_USER = DEFAULT_EVENTS_PER_USER\n",
        "ANOMALY_FRACTION = DEFAULT_ANOMALY_FRACTION\n",
        "RANDOM_STATE = DEFAULT_RANDOM_STATE\n",
        "PRECISION_K = 50\n",
        "THRESHOLD_PERCENTILE = 99.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate synthetic SOC events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = generate_synthetic_soc_dataset(\n",
        "    n_users=N_USERS,\n",
        "    events_per_user=EVENTS_PER_USER,\n",
        "    anomaly_fraction=ANOMALY_FRACTION,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(df):,} events with {df[LABEL_COL].sum():,} anomalies ({df[LABEL_COL].mean():.2%}).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quick peek at the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[FEATURE_COLS + [LABEL_COL]].describe().T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train/test preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    X_train_scaled,\n",
        "    X_test_scaled,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    scaler,\n",
        "    X_train_df,\n",
        "    X_test_df,\n",
        ") = prepare_train_test(\n",
        "    df,\n",
        "    feature_cols=FEATURE_COLS,\n",
        "    label_col=LABEL_COL,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "print(f\"Training samples (normal only): {X_train_scaled.shape[0]:,}\")\n",
        "print(f\"Test samples (normals + anomalies): {X_test_scaled.shape[0]:,}\")\n",
        "print(f\"Test anomaly fraction: {y_test.mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train IsolationForest & OneClassSVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iso_model = train_isolation_forest(\n",
        "    X_train_scaled,\n",
        "    contamination=ANOMALY_FRACTION,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "iso_scores = isolation_forest_scores(iso_model, X_test_scaled)\n",
        "\n",
        "ocsvm_model = train_oneclass_svm(\n",
        "    X_train_scaled,\n",
        "    nu=ANOMALY_FRACTION,\n",
        "    kernel=\"rbf\",\n",
        "    gamma=\"scale\",\n",
        ")\n",
        "ocsvm_scores = oneclass_svm_scores(ocsvm_model, X_test_scaled)\n",
        "\n",
        "print(\"Models trained and scoring arrays computed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Core metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iso_metrics = evaluate_model(\n",
        "    \"IsolationForest\",\n",
        "    y_test,\n",
        "    iso_scores,\n",
        "    k=PRECISION_K,\n",
        "    threshold_percentile=THRESHOLD_PERCENTILE,\n",
        ")\n",
        "\n",
        "ocsvm_metrics = evaluate_model(\n",
        "    \"OneClassSVM\",\n",
        "    y_test,\n",
        "    ocsvm_scores,\n",
        "    k=PRECISION_K,\n",
        "    threshold_percentile=THRESHOLD_PERCENTILE,\n",
        ")\n",
        "\n",
        "iso_metrics, ocsvm_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Global signals\n",
        "\n",
        "Correlate each feature with the IsolationForest anomaly scores (unscaled features) to see which attributes drive alerts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iso_corr = global_feature_correlations(\n",
        "    X_test_df=X_test_df,\n",
        "    y_test=y_test,\n",
        "    scores=iso_scores,\n",
        "    feature_cols=FEATURE_COLS,\n",
        "    score_col_name=\"iso_score\",\n",
        ")\n",
        "iso_corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=iso_corr.values, y=iso_corr.index, palette=\"coolwarm\")\n",
        "plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=0.8)\n",
        "plt.title(\"IsolationForest feature correlations\")\n",
        "plt.xlabel(\"Pearson correlation with anomaly score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Score distributions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
        "\n",
        "sns.histplot(\n",
        "    x=iso_scores,\n",
        "    hue=y_test,\n",
        "    bins=60,\n",
        "    ax=axes[0],\n",
        "    palette={0: \"#2ca02c\", 1: \"#d62728\"},\n",
        "    legend=True,\n",
        ")\n",
        "axes[0].set_title(\"IsolationForest scores\")\n",
        "axes[0].set_xlabel(\"Score (higher = more anomalous)\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "sns.histplot(\n",
        "    x=ocsvm_scores,\n",
        "    hue=y_test,\n",
        "    bins=60,\n",
        "    ax=axes[1],\n",
        "    palette={0: \"#2ca02c\", 1: \"#d62728\"},\n",
        "    legend=True,\n",
        ")\n",
        "axes[1].set_title(\"OneClassSVM scores\")\n",
        "axes[1].set_xlabel(\"Score (higher = more anomalous)\")\n",
        "axes[1].set_ylabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Confusion matrices at 99th percentile threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iso_preds = (iso_scores >= iso_metrics[\"threshold\"]).astype(int)\n",
        "ocsvm_preds = (ocsvm_scores >= ocsvm_metrics[\"threshold\"]).astype(int)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "for ax, preds, title in [\n",
        "    (axes[0], iso_preds, \"IsolationForest\"),\n",
        "    (axes[1], ocsvm_preds, \"OneClassSVM\"),\n",
        "]:\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"Normal\", \"Anomaly\"])\n",
        "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
        "    ax.set_title(title)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Local explanations (z-scores)\n",
        "\n",
        "Each event is compared against the mean/std of normal traffic to describe how extreme the top anomalies are.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means, stds = compute_feature_stats(X_train_df, FEATURE_COLS)\n",
        "local_explanations = explain_top_anomalies(\n",
        "    X_test_df=X_test_df,\n",
        "    y_test=y_test,\n",
        "    scores=iso_scores,\n",
        "    means=means,\n",
        "    stds=stds,\n",
        "    feature_cols=FEATURE_COLS,\n",
        "    top_m=10,\n",
        ")\n",
        "local_explanations[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explain_df = pd.DataFrame(local_explanations)\n",
        "explain_df[\"true_label\"] = explain_df[\"true_label\"].map({0: \"Normal\", 1: \"Anomaly\"})\n",
        "explain_df[[\"index\", \"true_label\", \"score\", \"explanations\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_counts = {}\n",
        "for expl_list in explain_df[\"explanations\"]:\n",
        "    for expl in expl_list:\n",
        "        feature = expl.split(\" is \")[0]\n",
        "        feature_counts[feature] = feature_counts.get(feature, 0) + 1\n",
        "\n",
        "feature_rank = pd.Series(feature_counts).sort_values(ascending=False)\n",
        "feature_rank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_rank.head(10).plot(kind=\"barh\", color=\"#ff7f0e\")\n",
        "plt.title(\"Most frequent deviant features (top anomalies)\")\n",
        "plt.xlabel(\"Frequency in top explanations\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Wrap-up\n",
        "\n",
        "Feel free to tweak the generation parameters (user count, anomaly fraction, random seed) and re-run the notebook to stress-test different SOC baselines.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
